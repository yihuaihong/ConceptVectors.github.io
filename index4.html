

<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- Here are the current paper tags:
1) tag-all (for all papers)
2) tag-privacy
3) tag-host-security
4) tag-network-security
5) tag-theoretical-foundations


-->
<html><head>
<title>Xinyun Chen's Homepage</title>
<style type="text/css">
body {
    margin-top: 30px;
    margin-bottom: 30px;
    margin-left: 100px;
    margin-right: 100px;
}
p {
    margin-top: 0px;
    margin-bottom: 0px;
}

.caption {
    font-size: 34px;
    font-weight: normal;
    color: #000;
    font-family: Constantia, "Lucida Bright", "DejaVu Serif", Georgia, serif;
}
.caption-1 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
}
.caption-2 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #990000;
}
.caption-3 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    font-weight: bold;
    color: #F00;
}

.caption-4 {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    color: #990000;
}
.content {
    font-size: 16px;
    font-family: Tahoma, Geneva, sans-serif;
    text-align: justify;
}

.title-small {
    font-size: 20px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #F90;
}
.title-large {
    font-size: 28px;
    font-family: Georgia, "Times New Roman", Times, serif;
    font-weight: bold;
    color: #000;
}
.margin {
    font-size: 10px;
    line-height: 10px;
}
.margin-small {
    font-size: 5px;
    line-height: 5px;
}
.margin-large {
    font-size: 16px;
    line-height: 16px;
}
</style>
<script type="text/javascript" src="https://jungyhuk.github.io/jquery.js"></script>     
<script type="text/javascript"> 

function displaypage(){
  $(".tag-all").hide();
  if(document.getElementById('tag-all-box').checked){
    $(".tag-all").show();
  }
  if(document.getElementById('tag-theoretical-foundations-box').checked){
    $(".tag-theoretical-foundations").show();
  }
  if(document.getElementById('tag-host-security-box').checked){
    $(".tag-host-security").show();
  }
  if(document.getElementById('tag-network-security-box').checked){
    $(".tag-network-security").show();
  }
  if(document.getElementById('tag-privacy-box').checked){
    $(".tag-privacy").show();
  }

}

$(document).ready(function() {    

$("#tag-all-box").click(function() {
  displaypage();
});   
$("#tag-theoretical-foundations-box").click(function() {
  displaypage();
});
$("#tag-host-security-box").click(function() {
  displaypage();
}); 
$("#tag-network-security-box").click(function() {
  displaypage();
}); 
$("#tag-privacy-box").click(function() {
  displaypage();
}); 

});             
</script>     
<meta http-equiv="Content-Type" content="text/html;charset=utf-8">
<meta name="GENERATOR" content="MSHTML 9.00.8112.16443"></head>
<body>

<table border="0" width="100%">
  <tbody>

    <tr>

    <td width="185"><table>
      <tr><td>
      <img src="static/picture/Xinyun.jpg" height="270" border="1"></td></tr>
      </table></td>
    <td width="15"></td>
    <td></td>
    <td><table border="0" width="100%">
      <tbody><tr height="10">
        <td colspan="2"></td></tr>


         <tr height="20">
        <td>
           <p class="caption">Xinyun Chen (陈 昕昀)</p>
           <p class="content"><strong>Email:</strong> xinyunchen at google dot com</p>
        </td>
      </tr>
      
      <tr height="40">
      <td>
      <p class="margin">&nbsp;</p>
       <p class="content">I am a senior research scientist at Google DeepMind. My research interests are large language models, code generation, and AI security.
       <br><br>
       I obtained my Ph.D. degree in Computer Science from UC Berkeley in 2022, and my B.S. degree in Computer Science from ACM Honored Class, Shanghai Jiao Tong University. I also spent time in Meta AI Research and National Institute of Informatics.
       </p>
      </td></tr>

      <tr height="20">
        <td>
          <p class="margin">&nbsp;</p>
          <p class="content"><strong><a href="#publications">Publications</a></strong>  [<strong><a href="https://scholar.google.com/citations?user=d4W1UT0AAAAJ&hl=en">Google Scholar</a></strong>] | <strong><a href="#awards">Awards</a></strong> | <strong><a href="#education">Education</a></strong> | <strong><a href="#talk">Talks</a></strong> | <strong><a href="#services">Services</a></strong> | <strong><a href="#teaching">Teaching</a></strong> | <strong><a href="#misc">Misc.</a></strong></p>
        </td>
      </tr>
      <tr height="20">
        <td colspan="2"></td></tr>
    </tbody></table></td>
  </tr>
</tbody></table>

<h2 class="label"><p class="title-large"><a name="publications"><span>Publications </span></a></p></h2>
<ul>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2402.08939"><strong>Premise Order Matters in Reasoning with Large Language Models</strong></a></p>
    <p class="content"><strong>Xinyun Chen*</strong>, Ryan A. Chi*, Xuezhi Wang, Denny Zhou. (* Equal contribution)</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2402.09727"><strong>A Human-Inspired Reading Agent with Gist Memory of Very Long Contexts</strong></a></p>
    <p class="content">Kuang-Huei Lee, <strong>Xinyun Chen</strong>, Hiroki Furuta, John Canny, Ian Fischer.</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2312.04474"><strong>Chain of Code: Reasoning with a Language Model-Augmented Code Emulator</strong></a></p>
    <p class="content">Chengshu Li, Jacky Liang, Andy Zeng, <strong>Xinyun Chen</strong>, Karol Hausman, Dorsa Sadigh, Sergey Levine, Li Fei-Fei, Fei Xia, Brian Ichter.</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="http://arxiv.org/abs/2304.05128"><strong>Teaching Large Language Models to Self-Debug</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Maxwell Lin, Nathanael Schärli, Denny Zhou.</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2309.03409"><strong>Large Language Models as Optimizers</strong></a></p>
    <p class="content">Chengrun Yang*, Xuezhi Wang, Yifeng Lu, Hanxiao Liu,  Quoc V. Le, Denny Zhou, <strong>Xinyun Chen*</strong>. (* Equal contribution)</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2310.01798"><strong>Large Language Models Cannot Self-Correct Reasoning Yet</strong></a></p>
    <p class="content">Jie Huang, <strong>Xinyun Chen</strong>, Swaroop Mishra, Huaixiu Steven Zheng, Adams Wei Yu, Xinying Song, Denny Zhou.</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2310.01714"><strong>Large Language Models as Analogical Reasoners</strong></a></p>
    <p class="content">Michihiro Yasunaga, <strong>Xinyun Chen</strong>, Yujia Li, Panupong Pasupat, Jure Leskovec, Percy Liang, Ed H. Chi, Denny Zhou.</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2310.06117"><strong>Take a Step Back: Evoking Reasoning via Abstraction in Large Language Models</strong></a></p>
    <p class="content">Huaixiu Steven Zheng*, Swaroop Mishra*, <strong>Xinyun Chen</strong>, Heng-Tze Cheng, Ed H. Chi, Quoc V Le, Denny Zhou. (* Equal contribution)</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2305.17126"><strong>Large Language Models as Tool Makers</strong></a></p>
    <p class="content">Tianle Cai, Xuezhi Wang, Tengyu Ma, <strong>Xinyun Chen</strong>, Denny Zhou.</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2305.14705"><strong>Mixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models</strong></a></p>
    <p class="content">Sheng Shen, Le Hou, Yanqi Zhou, Nan Du, Shayne Longpre, Jason Wei, Hyung Won Chung, Barret Zoph, William Fedus, <strong>Xinyun Chen</strong>, Tu Vu, Yuexin Wu, Wuyang Chen, Albert Webson, Yunxuan Li, Vincent Zhao, Hongkun Yu, Kurt Keutzer, Trevor Darrell, Denny Zhou.</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2402.09371"><strong>Transformers Can Achieve Length Generalization But Not Robustly</strong></a></p>
    <p class="content">Yongchao Zhou, Uri Alon, <strong>Xinyun Chen</strong>, Xuezhi Wang, Rishabh Agarwal, Denny Zhou.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2402.03620"><strong>Self-Discover: Large Language Models Self-Compose Reasoning Structures</strong></a></p>
    <p class="content">Pei Zhou, Jay Pujara, Xiang Ren, <strong>Xinyun Chen</strong>,  Heng-Tze Cheng, Quoc V. Le, Ed H. Chi, Denny Zhou, Swaroop Mishra, Huaixiu Steven Zheng.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2311.17311"><strong>Universal Self-Consistency for Large Language Model Generation</strong></a></p>
    <p class="content"><strong>Xinyun Chen*</strong>, Renat Aksitov*, Uri Alon, Jie Ren, Kefan Xiao, Pengcheng Yin, Sushant Prakash, Charles Sutton, Xuezhi Wang, Denny Zhou. (* Equal contribution)</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2310.07064"><strong>Large Language Models can Learn Rules</strong></a></p>
    <p class="content">Zhaocheng Zhu, Yuan Xue, <strong>Xinyun Chen</strong>, Denny Zhou, Jian Tang, Dale Schuurmans, Hanjun Dai.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2210.11416"><strong>Scaling Instruction-Finetuned Language Models</strong></a></p>
    <p class="content">Hyung Won Chung*, Le Hou*, Shayne Longpre*, Barret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, Albert Webson, Shixiang Shane Gu, Zhuyun Dai, Mirac Suzgun, <strong>Xinyun Chen</strong>, Aakanksha Chowdhery, Sharan Narang, Gaurav Mishra, Adams Yu, Vincent Zhao, Yanping Huang, Andrew Dai, Hongkun Yu, Slav Petrov, Ed H. Chi, Jeff Dean, Jacob Devlin, Adam Roberts, Denny Zhou, Quoc V. Le, Jason Wei*. (* Equal contribution)</p>
      <p class="content">Journal of Machine Learning Research (<strong>JMLR</strong>), 2024.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2302.00093"><strong>Large Language Models Can Be Easily Distracted by Irrelevant Context</strong></a></p>
    <p class="content">Freda Shi*, <strong>Xinyun Chen*</strong>, Kanishka Misra, Nathan Scales, David Dohan, Ed Chi, Nathanael Schärli, Denny Zhou. (* Equal contribution)</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2209.15003"><strong>Compositional Semantic Parsing with Large Language Models</strong></a></p>
    <p class="content">Andrew Drozdov*, Nathanael Schärli*, Ekin Akyürek, Nathan Scales, Xinying Song, <strong>Xinyun Chen</strong>, Olivier Bousquet, Denny Zhou. (* Equal contribution)</p>
    <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2305.08298"><strong>Symbol tuning improves in-context learning in language models</strong></a></p>
    <p class="content">Jerry Wei, Le Hou, Andrew Lampinen, Xiangning Chen, Da Huang, Yi Tay, <strong>Xinyun Chen</strong>, Yifeng Lu, Denny Zhou, Tengyu Ma, Quoc V. Le.</p>
      <p class="content">Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2303.03846"><strong>Larger Language Models Do In-Context Learning Differently</strong></a></p>
    <p class="content">Jerry Wei, Jason Wei, Yi Tay, Dustin Tran, Albert Webson, Yifeng Lu, <strong>Xinyun Chen</strong>, Hanxiao Liu, Da Huang, Denny Zhou, Tengyu Ma.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2012.01654"><strong>Towards Defending Multiple Lp-norm Bounded Adversarial Perturbations via Gated Batch Normalization</strong></a></p>
    <p class="content">Aishan Liu, Shiyu Tang, <strong>Xinyun Chen</strong>, Lei Huang, Haotong Qin, Xianglong Liu, Dacheng Tao.</p>
      <p class="content">International Journal of Computer Vision (<strong>IJCV</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://aclanthology.org/2023.findings-acl.53/"><strong>Re-appraising the Schema Linking for Text-to-SQL</strong></a></p>
    <p class="content">Yujian Gan, <strong>Xinyun Chen</strong>, Matthew Purver.</p>
      <p class="content">Findings of the Association for Computational Linguistics (<strong>ACL Findings</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2304.00409"><strong>DiverseVul: A New Vulnerable Source Code Dataset for Deep Learning Based Vulnerability Detection</strong></a></p>
    <p class="content">Yizheng Chen, Zhoujie Ding, Lamya Alowain, <strong>Xinyun Chen</strong>, David Wagner.</p>
      <p class="content">nternational Symposium on Research in Attacks, Intrusions and Defenses (<strong>RAID</strong>), 2023.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2308.16458"><strong>BioCoder: A Benchmark for Bioinformatics Code Generation with Contextual Pragmatic Knowledge</strong></a></p>
    <p class="content">Xiangru Tang*, Bill Qian*, Rick Gao*, Jiakang Chen*, <strong>Xinyun Chen</strong>, Mark Gerstein. (* Equal contribution)</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2203.07814"><strong>Competition-Level Code Generation with AlphaCode</strong></a></p>
    <p class="content">Yujia Li*, David Choi*, Junyoung Chung*, Nate Kushman*, Julian Schrittwieser*, Rémi Leblond*, Tom Eccles*, James Keeling*, Felix Gimeno*, Agustin Dal Lago*, Thomas Hubert*, Peter Choy*, Cyprien de Masson d'Autume*, Igor Babuschkin, <strong>Xinyun Chen</strong>, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, Oriol Vinyals. (* Joint first authors).</p>
      <p class="content"><strong>Science Magazine</strong>, 2022.</p>
    <p class="content">
        Featured as the front cover in <a href="https://www.science.org/toc/science/378/6624">Science Magazine</a>. AlphaCode achieved an estimated rank within the top 54% of participants in programming competitions. Please check out the <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode">DeepMind blog post</a> for more details.
    </p>
</li>

<br>

<li>
    <p class="content"><a href="static/file/qt74d6s4sd.pdf"><strong>Learning-Based Program Synthesis: Towards Synthesizing Complex Programs from Multi-Modal Specifications in the Wild</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>.</p>
      <p class="content">Ph.D. Dissertation, 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2210.14473"><strong>Benchmarking Language Models for Code Syntax Understanding</strong></a></p>
    <p class="content">Da Shen, <strong>Xinyun Chen</strong>, Chenguang Wang, Koushik Sen, Dawn Song.</p>
      <p class="content">Findings of Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP Findings</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://openreview.net/pdf?id=BlbhyDUo9xc"><strong>Perturbation Type Categorization for Multiple Adversarial Perturbation Robustness</strong></a></p>
    <p class="content">Pratyush Maini, <strong>Xinyun Chen</strong>, Bo Li, Dawn Song.</p>
      <p class="content">Conference on Uncertainty in Artificial Intelligence (<strong>UAI</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2012.10544"><strong>Dataset Security for Machine Learning: Data Poisoning, Backdoor Attacks, and Defenses</strong></a></p>
    <p class="content">Micah Goldblum, Dimitris Tsipras, Chulin Xie, <strong>Xinyun Chen</strong>, Avi Schwarzschild, Dawn Song, Aleksander Madry, Bo Li, Tom Goldstein.</p>
    <p class="content">IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2110.14890"><strong>SMORE: Knowledge Graph Completion and Multi-hop Reasoning in Massive Knowledge Graphs</strong></a></p>
    <p class="content">Hongyu Ren, Hanjun Dai, Bo Dai, <strong>Xinyun Chen</strong>, Denny Zhou, Jure Leskovec, Dale Schuurmans.</p>
      <p class="content">ACM SIGKDD Conference on Knowledge Discovery & Data Mining (<strong>KDD</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2205.02054"><strong>Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment</strong></a></p>
    <p class="content">Yujian Gan, <strong>Xinyun Chen</strong>, Qiuping Huang, Matthew Purver.</p>
      <p class="content">Findings of Annual Conference of the North American Chapter of the Association for Computational Linguistics (<strong>NAACL Findings</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2112.09174"><strong>Learning Bounded Context-Free Grammar via LSTM and the Transformer: Difference and Explanations
</strong></a></p>
    <p class="content">Hui Shi, Sicun Gao, Yuandong Tian, <strong>Xinyun Chen</strong>, Jishen Zhao.</p>
    <p class="content">AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2022.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2107.00101"><strong>Latent Execution for Neural Program Synthesis
</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Dawn Song, Yuandong Tian.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="http://proceedings.mlr.press/v139/chen21m.html"><strong>SpreadsheetCoder: Formula Prediction from Semi-structured Context
</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Petros Maniatis, Rishabh Singh, Charles Sutton, Hanjun Dai, Max Lin, Denny Zhou.</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2021.</p>
      <p class="content">
        Our work was released to support <a href="https://workspaceupdates.googleblog.com/2021/08/intelligent-formula-and-function-suggestions-in-google-sheets.html"><strong>Google Sheets formula suggestions</strong></a>. Please check out our <a href="https://ai.googleblog.com/2021/10/predicting-spreadsheet-formulas-from.html">Google AI blog</a> for more details.
      </p>
</li>

<br>

<li>
    <p class="content"><a href="http://proceedings.mlr.press/v139/ren21a.html"><strong>LEGO: Latent Execution-Guided Reasoning for Multi-Hop Question Answering on Knowledge Graphs</strong></a></p>
    <p class="content">Hongyu Ren, Hanjun Dai, Bo Dai, <strong>Xinyun Chen</strong>, Michihiro Yasunaga, Haitian Sun, Dale Schuurmans, Jure Leskovec, Denny Zhou.</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="http://proceedings.mlr.press/v139/fu21a.html"><strong>Learn-to-Share: A Hardware-friendly Transfer Learning Framework Exploiting Computation and Parameter Sharing</strong></a></p>
    <p class="content">Cheng Fu, Hanxian Huang, <strong>Xinyun Chen</strong>, Yuandong Tian, Jishen Zhao.</p>
    <p class="content">International Conference on Machine Learning (<strong>ICML</strong>), 2021. (<strong>Long Talk</strong>)</p>
</li>

<br>

<li>
    <p class="content"><a href="https://aclanthology.org/2021.acl-long.169/"><strong>PlotCoder: Hierarchical Decoding for Synthesizing Visualization Code in Programmatic Context</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Linyuan Gong, Alvin Cheung, Dawn Song.</p>
    <p class="content">Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://aclanthology.org/2021.acl-long.195/"><strong>Towards Robustness of Text-to-SQL Models against Synonym Substitution</strong></a></p>
    <p class="content">Yujian Gan, <strong>Xinyun Chen</strong>, Qiuping Huang, Matthew Purver, John R. Woodward, Jinxia Xie, Pengsheng Huang.</p>
    <p class="content">Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/1911.07205"><strong>REFIT: a Unified Watermark Removal Framework for Deep Learning Systems with Limited Data</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>*, Wenxiao Wang*, Chris Bender, Yiming Ding, Ruoxi Jia, Bo Li, Dawn Song. (* Equal contribution)</p>
      <p class="content">ACM Asia Conference on Computer and Communications Security (<strong>AsiaCCS</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2109.05157"><strong>Exploring Underexplored Limitations of Cross-Domain Text-to-SQL Generalization</strong></a></p>
    <p class="content">Yujian Gan, <strong>Xinyun Chen</strong>, Matthew Purver.</p>
      <p class="content">Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2109.05153"><strong>Natural SQL: Making SQL Easier to Infer from Natural Language Specifications</strong></a></p>
    <p class="content">Yujian Gan, <strong>Xinyun Chen</strong>, Jinxia Xie, Matthew Purver, John R. Woodward, John Drake, Qiaofu Zhang.</p>
      <p class="content">Findings of Conference on Empirical Methods in Natural Language Processing (<strong>EMNLP Findings</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2102.13170"><strong>Understanding Robustness in Teacher-Student Setting: A New Perspective</strong></a></p>
    <p class="content">Zhuolin Yang*, Zhaoxi Chen, Tiffany (Tianhui) Cai, <strong>Xinyun Chen</strong>, Bo Li, Yuandong Tian*. (* Equal contribution)</p>
      <p class="content">International Conference on Artificial Intelligence and Statistics (<strong>AISTATS</strong>), 2021.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2109.05211"><strong>RobustART: Benchmarking Robustness on Architecture Design and Training Techniques
</strong></a></p>
    <p class="content">Shiyu Tang, Ruihao Gong, Yan Wang, Aishan Liu, Jiakai Wang, <strong>Xinyun Chen</strong>, Fengwei Yu, Xianglong Liu, Dawn Song, Alan Yuille, Philip H.S. Torr, Dacheng Tao.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2008.06662"><strong>Compositional Generalization via Neural-Symbolic Stack Machines</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Chen Liang, Adams Wei Yu, Dawn Song, Denny Zhou.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2007.08095"><strong>Synthesize, Execute and Debug: Learning to Repair for Neural Program Synthesis</strong></a></p>
    <p class="content">Kavi Gupta, Peter Ebert Christensen*, <strong>Xinyun Chen</strong>*, Dawn Song. (* Equal contribution)</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2020.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/2005.09161"><strong>Spatiotemporal Attacks for Embodied Agents</strong></a></p>
    <p class="content">Aishan Liu, Tairan Huang, Xianglong Liu, Yitao Xu, Yuqing Ma, <strong>Xinyun Chen</strong>, Stephen Maybank, Dacheng Tao.</p>
      <p class="content">European Conference on Computer Vision (<strong>ECCV</strong>), 2020.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://openreview.net/forum?id=ryxjnREFwH"><strong>Neural Symbolic Reader: Scalable Integration of Distributed and Symbolic Representations for Reading Comprehension</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Chen Liang, Adams Wei Yu, Denny Zhou, Dawn Song, Quoc V. Le.</p>
      <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2020. (<strong>Spotlight</strong>)</p>
</li>

<br>

<li>
    <p class="content"><a href="https://openreview.net/forum?id=r1egIyBFPS&noteId=r1egIyBFPS"><strong>Deep Symbolic Superoptimization Without Human Knowledge</strong></a></p>
    <p class="content">Hui Shi, Yang Zhang, <strong>Xinyun Chen</strong>, Yuandong Tian, Jishen Zhao.</p>
      <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2020.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/1810.00337"><strong>Learning to Perform Local Rewriting for Combinatorial Optimization
</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Yuandong Tian.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2019.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/1906.12029"><strong>Coda: An End-to-End Neural Program Decompiler</strong></a></p>
    <p class="content">Cheng Fu, Huili Chen, Haolan Liu, <strong>Xinyun Chen</strong>, Yuandong Tian, Farinaz Koushanfar, Jishen Zhao.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2019.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://openreview.net/forum?id=H1gfOiAqYm&noteId=H1gfOiAqYm"><strong>Execution-Guided Neural Program Synthesis</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Chang Liu, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2019.</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/1802.03691"><strong>Tree-to-tree Neural Networks for Program Translation</strong></a></p>
    <p class="content"><strong>Xinyun Chen</strong>, Chang Liu, Dawn Song.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2018.</p>
     <p class="margin-small">&nbsp;</p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1709.08693"><strong>Fooling Vision and Language Models Despite Localization and Attention Mechanism</strong></a></p>
      <p class="content">Xiaojun Xu, <strong>Xinyun Chen</strong>, Chang Liu, Anna Rohrbach, Trevor Darrell, Dawn Song.</p>
      <p class="content">IEEE Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2018</p>
</li>

<br>

<li>
    <p class="content"><a href="https://arxiv.org/abs/1706.01284"><strong>Towards Synthesizing Complex Programs from Input-Output Examples</strong></a></p>
      <p class="content"><strong>Xinyun Chen</strong>, Chang Liu, Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2018.</p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1712.05526"><strong>Targeted Backdoor Attacks on Deep Learning Systems Using Data Poisoning</strong></a></p>
      <p class="content"><strong>Xinyun Chen</strong>, Chang Liu, Bo Li, Kimberly Lu, Dawn Song.</p>
      <p class="content">
        <strong>Media coverage:</strong> <a href="https://motherboard.vice.com/en_us/article/yw5dng/how-to-turn-a-pair-of-glasses-into-an-ai-fooling-spy-tool">Motherboard</a> | <a href="https://www.theregister.co.uk/2017/12/20/fool_ai_facial_recognition_poison/">The Register</a>
      </p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1706.04701"><strong>Adversarial Example Defenses: Ensembles of Weak Defenses are not Strong</strong></a></p>
      <p class="content">Warren He, James Wei, <strong>Xinyun Chen</strong>, Nicholas Carlini, Dawn Song.</p>
      <p class="content">USENIX Workshop on Offensive Technologies (WOOT), 2017.</p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1611.02770"><strong>Delving into Transferable Adversarial Examples and Black-box Attacks</strong></a></p>
      <p class="content">Yanpei Liu, <strong>Xinyun Chen</strong>, Chang Liu, and Dawn Song.</p>
      <p class="content">International Conference on Learning Representations (<strong>ICLR</strong>), 2017.</p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1604.02606"><strong>A General Retraining Framework for Scalable Adversarial Classification</strong></a></p>
      <p class="content">Bo Li, Yevgeniy Vorobeychik, <strong>Xinyun Chen</strong>.</p>
      <p class="content">NeurIPS Workshop on Adversarial Training, 2016.</p>
</li>

<br>

<li>
      <p class="content"><a href="https://arxiv.org/abs/1611.01867"><strong>Latent Attention For If-Then Program Synthesis</strong></a></p>
      <p class="content"><strong>Xinyun Chen</strong>, Chang Liu, Richard Shin, Dawn Song, Mingcheng Chen.</p>
      <p class="content">Advances in Neural Information Processing Systems (<strong>NeurIPS</strong>), 2016.</p>
</li>

</ul>


<h2 class="label"><p class="title-large"><a name="awards"><span>Honors and Awards</span></a></p></h2>
<ul>
<li><p class="content"><a href="https://ml.umd.edu/rising-stars/">Rising Stars in Machine Learning</a>, 2021.</p></li>
<li><p class="content"><a href="https://risingstars21-eecs.mit.edu/">Rising Stars in EECS</a>, 2021.</p></li>
<li><p class="content"><a href="https://research.fb.com/fellows/?dateYear=2020">Facebook Fellowship</a>, 2020 (<a href="https://research.fb.com/blog/2021/07/facebook-fellow-spotlight-shaping-the-future-with-neural-program-synthesis-and-adversarial-ml/">blog spotlight</a>).</p></li>
<li><p class="content"><a href="https://eecs.berkeley.edu/rising-stars-2020">Rising Stars in EECS</a>, 2020.</p></li>
<li><p class="content">Departmental Fellowship of EECS, UC Berkeley, 2017.</p></li>
<li><p class="content">The Prize of Excellent Bachelor Thesis (top 1% in Shanghai Jiao Tong University), 2017.</p></li>
<li><p class="content">Outstanding Graduate of Shanghai Jiao Tong University, 2017.</p></li>
<li><p class="content">Gold Medal of Asia-Pacific Informatics Olympiad in China District, 2012.</p></li>
<li><p class="content">Silver Medal of Chinese Team Selection Contest, 2012.</p></li>
</ul>


<h2 class="label"><p class="title-large"><a name="education"><span>Education</span></a></p></h2>
<ul>
<li><p class="content">Aug 2017 - May 2022: Ph.D., Computer Science, UC Berkeley. Advisor: Prof. <a href="https://people.eecs.berkeley.edu/~dawnsong/">Dawn Song</a>.</p></li>
<li><p class="content">Sep 2013 - Jun 2017: B.S., ACM Honored Class, Shanghai Jiao Tong University. Rank: 1/30.</p></li>
</ul>

<h2 class="label"><p class="title-large"><a name="talk"><span>Talks</span></a></p></h2>
<ul>
<li><p class="content">May 2024: <strong>Self-Improvement with Large Language Models</strong>, <a href="https://www.upperbound.ai/">Upper Bound 2024</a>.</p></li>
<li><p class="content">May 2024: <strong>Self-Improvement with Large Language Models</strong>, <a href="https://cmu-agent-workshop.github.io/">CMU Agent Workshop</a>.</p></li>
<li><p class="content">December 2023: <strong>Self-Improvement with Large Language Models</strong>, <a href="https://sslneurips23.github.io/index.html">NeurIPS Workshop on Self-Supervised Learning - Theory and Practice</a>.</p></li>
<li><p class="content">December 2023: <strong>Analogical Reasoning with Large Language Models</strong>, <a href="https://mathai2023.github.io/">NeurIPS Workshop on Mathematical Reasoning and AI</a>.</p></li>
<li><p class="content">December 2023: <strong>Self-Debugging with Large Language Models</strong>, <a href="https://sites.google.com/view/fmdm-neurips23/">NeurIPS Workshop on Foundation Models for Decision Making</a>.</p></li>
<li><p class="content">November 2023: <strong>Self-Improvement with Large Language Models</strong>, <a href="https://www.aicamp.ai/">AICamp Seminar</a>.</p></li>
<li><p class="content">October 2023: <strong>Large Language Models for Code Generation</strong>, <a href="https://dataphoenix.info/webinars/">Data Phoenix webinar</a>.</p></li>
<li><p class="content">October 2023: <strong>Large Language Models for Code Generation</strong>, guest lecture in <a href="https://rdi.berkeley.edu/responsible-genai/f23">CS294/194-196: Responsible GenAI and Decentralized Intelligence</a>, UC Berkeley.</p></li>
<li><p class="content">August 2023: <strong>Leveraging Execution Feedback for Program Synthesis with Large Language Models</strong>, <a href="https://ai4code.notion.site/ai4code/LLMs-for-Code-Seminar-c22883e19dc34cbba89198c8fc88c506">LLMs for Code Seminar</a>.</p></li>
<li><p class="content">April 2023: <strong>Adversarial Learning Meets Large Language Models</strong>, <a href="https://research.csiro.au/cybersecurity-quantum-systems/our-sao-seminars/">SAO seminar</a>, CSIRO.</p></li>
<li><p class="content">April 2023: <strong>Language Models for Program Synthesis</strong>, guest lecture in CPSC 663: Deep Learning Theory and Applications, Yale University.</p></li>
<li><p class="content">February 2023: <strong>Learning-Based Program Synthesis</strong>, <a href="https://ai-west-dl.re-work.co/schedule">REWORK Deep Learning Summit</a>.</p></li>
<li><p class="content">December 2022: <strong>Program Synthesis from Semi-Structured Context</strong>, <a href="https://table-representation-learning.github.io/">NeurIPS Workshop on Table Representation Learning</a>.</p></li>
<li><p class="content">November 2022: <strong>Learning-Based Program Synthesis</strong>, guest lecture in CSE 527A: Natural Language Processing, Washington University in St. Louis.</p></li>
<li><p class="content">November 2022: <strong>Learning-Based Program Synthesis</strong>, Amazon AWS AI Research.</p></li>
<li><p class="content">October 2022: <strong>Learning-Based Program Synthesis</strong>, guest lecture in <a href="http://www.cs.umd.edu/class/fall2022/cmsc828W/">CMSC 828W: Foundations of Deep Learning</a>, University of Maryland.</p></li>
<li><p class="content">September 2022: <strong>Learning to Model Structures and Execution for Program Synthesis</strong>, <a href="https://www.cs.cmu.edu/calendar/162376157">Language Technologies Institute Topical Seminar</a>, Carnegie Mellon University.</p></li>
<li><p class="content">April 2022: <strong>Learning to Model Structures and Execution for Program Synthesis</strong>, <a href="https://dl4c.github.io/">ICLR Workshop on Deep Learning For Code</a>.</p></li>
<li><p class="content">April 2022: <strong>Program Synthesis via Learning</strong>, guest lecture in <a href="https://inst.eecs.berkeley.edu/~cs188/sp22/">CS188: Introduction to Artificial Intelligence</a>, UC Berkeley.</p></li>
<li><p class="content">December 2021: <strong>Learning-Based Program Synthesis</strong>, Microsoft New England Machine Learning Seminar.</p></li>
<li><p class="content">December 2021: <strong>Learning-Based Program Synthesis</strong>, Microsoft Research Asia.</p></li>
<li><p class="content">November 2021: <strong>Deep Learning for Program Synthesis: Towards Human-like Reasoning</strong>, <a href="https://ml.umd.edu/rising-stars/">ML Rising Stars Series</a>, University of Maryland.</p></li>
<li><p class="content">October 2021: <strong>Neural Program Synthesis for Language Understanding in the Wild</strong>, <a href="http://www.neurosymbolic.org/events.html">Neurosym Webinar Series</a>.</p></li>
<li><p class="content">October 2021: <strong>Deep Learning for Program Synthesis: Towards Human-like Reasoning</strong>, Stanford Software Research Lunch.</p></li>
<li><p class="content">September 2021: <strong>Deep Learning for Program Synthesis: Towards Human-like Reasoning</strong>, Facebook Fellowship Summit.</p></li>
<li><p class="content">August 2021: <strong>Deep Learning for Program Synthesis: Towards Human-like Reasoning</strong>, University of Southern California.</p></li>
<li><p class="content">June 2021: <strong>Adversarial Attacks in Computer Vision: An Overview</strong>, <a href="https://advmlincv.github.io/cvpr21-tutorial/">CVPR Tutorial on Adversarial Machine Learning in Computer Vision</a>.</p></li>
<li><p class="content">April 2021: <strong>Deep Learning for Program Synthesis</strong>, SJSU SCE Spark Tech Conference.</p></li>
<li><p class="content">March 2021: <strong>Neural-Symbolic Reasoning for Language Understanding</strong>, <a href="https://mrc2021.github.io/">WSDM Workshop on Machine Reasoning</a>.</p></li>
<li><p class="content">December 2020: <strong>Deep Learning for Program Synthesis from Input-Output Examples</strong>, <a href="https://capworkshop.github.io/">NeurIPS Workshop on Computer-Assisted Programming</a>.</p></li>
<li><p class="content">June 2020: <strong>Neural Program Synthesis for Navigation and Language Understanding</strong>, <a href="http://nscv.csail.mit.edu/">CVPR Tutorial on Neuro-Symbolic Visual Reasoning and Program Synthesis</a>.</p></li>
<li><p class="content">October 2019: <strong>Neural Program Synthesis from Natural Language Specification</strong>, <a href="https://oval.cs.stanford.edu/seminar/aut2019.html">Open Virtual Assistant Lab</a>, Stanford University.</p></li>
<li><p class="content">February 2019: <strong>Neural Program Synthesis from Input-Output Examples</strong>, UC San Diego.</p></li>
<li><p class="content">November 2018: <strong>Towards Synthesizing Complex Programs from Input-Output Examples</strong>, guest lecture in <a href="https://sites.google.com/view/program-synthesis/">CS294-157: Deep Learning and Program Synthesis</a>, UC Berkeley.</p></li>
<li><p class="content">October 2018: <strong>Neural Program Synthesis from Input-Output Examples</strong>, Facebook Big Code Summit.</p></li>
<li><p class="content">May 2018: <strong>Deep Learning for Program Synthesis</strong>, guest lecture in <a href="https://web.stanford.edu/class/cs379c/archive/2018/index.html">CS379C: Computational Models of the Neocortex</a>, Stanford University.</p></li>
</ul>

<h2 class="label"><p class="title-large"><a name="services"><span>Services</span></a></p></h2>
<ul>
<li><p class="content">Co-organizer of the Workshop on <a href="https://llmagents.github.io/"><strong>LLM Agents</strong></a> at ICLR 2024.</p></li>
<li><p class="content">Co-chair of <a href="https://aisec.cc/"><strong>AISec Workshop</strong></a> at CCS 2022-2024.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://cvpr24-advml.github.io/"><strong>Adversarial Machine Learning on Computer Vision: Robustness of Foundation Models</strong></a> at CVPR 2024.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://robustart.github.io/"><strong>Adversarial Machine Learning
on Computer Vision: Art of Robustness</strong></a> at CVPR 2023.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://suki-workshop.github.io/"><strong>Structured and Unstructured Knowledge Integration</strong></a> at NAACL 2022.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://artofrobust.github.io/"><strong>The Art of Robustness:
Devil and Angel in Adversarial Machine Learning</strong></a> at CVPR 2022.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://eccv22-arow.github.io/"><strong>Workshop on Adversarial Robustness in the Real World</strong></a> at ECCV 2022.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://practical-dl.github.io/"><strong>Practical Deep Learning in the Wild</strong></a> at AAAI 2022.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://aisecure-workshop.github.io/aml-iclr2021/"><strong>Security and Safety in Machine Learning Systems</strong></a> at ICLR 2021.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://aisecure-workshop.github.io/amlcvpr2021/"><strong>Adversarial Machine
Learning in Real-World Computer Vision Systems and Online Challenges</strong></a> at CVPR 2021.</p></li>
<li><p class="content">Co-organizer of the Tutorial on <a href="https://advmlincv.github.io/cvpr21-tutorial/"><strong>Adversarial Machine Learning in Computer Vision</strong></a> at CVPR 2021.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://icmlsrml2021.github.io/"><strong>Socially Responsible Machine Learning</strong></a> at ICML 2021.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://iccv21-adv-workshop.github.io/"><strong>Adversarial Robustness in the Real World</strong></a> at ICCV 2021.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://advm-workshop-2021.github.io/"><strong>Adversarial
Learning for Multimedia</strong></a> at ACM Multimedia 2021.</p></li>
<li><p class="content">Co-organizer of the Workshop on <a href="https://adv-workshop-2020.github.io/"><strong>Adversarial Machine Learning in Computer Vision</strong></a> at CVPR 2020.</p></li>
<li><p class="content">Area Chair of <a href="https://colmweb.org/index.html"><strong>COLM 2024</strong>.</a></p></li>
<li><p class="content">Program Committee / Reviewer of: NeurIPS (Outstanding Reviewer Award in 2020 and 2021), ICLR (Notable Reviewer Award in 2023), IJCAI (senior PC in 2021), ICML (expert reviewer in 2021), AAAI, ACL, EMNLP, NAACL, ICCV, ECCV, TPAMI, IJCV, TIP, TIFS, TDSC.</p></li>
</ul>

<h2 class="label"><p class="title-large"><a name="teaching"><span>Teaching</span></a></p></h2>
<ul>
<li><p class="content">Graduate Student Instructor of <a href="http://rail.eecs.berkeley.edu/deeprlcourse/">CS 285: Deep Reinforcement Learning</a>, Fall 2021, UC Berkeley.</p></li>
<li><p class="content">Graduate Student Instructor of <a href="https://inst.eecs.berkeley.edu/~cs188/sp21/">CS 188: Introduction to Artificial Intelligence</a>, Spring 2021, UC Berkeley.</p></li>
</ul>

<h2 class="label"><p class="title-large"><a name="misc"><span>Miscellaneous</span></a></p></h2>

<ul>
<p class="content">In my spare time, I enjoy listening to all kinds of music. I have played the piano since kindergarten, and received the highest-level certificates of piano and music theory in China. I used to play some other instruments, including recorder and harmonica.</p>
</ul>
</body></html> 
