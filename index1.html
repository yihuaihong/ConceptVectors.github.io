<!doctype html><html lang="en" class="no-js"><head><meta name="google-site-verification" content="dSs91yaMZFstcVLxzwBo4NGnkZcLMDgV4LDPJ13WFjE"><meta name="google-site-verification" content="IdeLCPxHTXJ0OOEM05vk7UAv72xQh5b7NFrEZAYcJH4"> <!-- dSs91yaMZFstcVLxzwBo4NGnkZcLMDgV4LDPJ13WFjE --><meta charset="utf-8"> <!-- begin SEO --><title> Pratyush Maini</title><meta property="og:locale" content="en-US"><meta property="og:site_name" content="Pratyush Maini"><meta property="og:title" content="Pratyush Maini"><link rel="canonical" href=""><meta property="og:url" content="https://pratyushmaini.github.io/"><meta property="og:description" content="About me"> <script type="application/ld+json"> { "@context" : "http://schema.org", "@type" : "Person", "name" : "Pratyush Maini", "url" : "https://pratyushmaini.github.io", "sameAs" : null } </script><meta name="google-site-verification" content="IdeLCPxHTXJ0OOEM05vk7UAv72xQh5b7NFrEZAYcJH4"> <!-- end SEO --><link href="https://pratyushmaini.github.io/feed.xml" type="application/atom+xml" rel="alternate" title="Pratyush Maini Feed"> <!-- http://t.co/dKP3o1e --><meta name="HandheldFriendly" content="True"><meta name="MobileOptimized" content="320"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="google-site-verification" content="dSs91yaMZFstcVLxzwBo4NGnkZcLMDgV4LDPJ13WFjE"><meta name="google-site-verification" content="IdeLCPxHTXJ0OOEM05vk7UAv72xQh5b7NFrEZAYcJH4"> <script> document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js '; </script> <!-- For all browsers --><link rel="stylesheet" href="static/css/main.css"><meta http-equiv="cleartype" content="on"> <!-- start custom head snippets --><link rel="apple-touch-icon" sizes="57x57" href="https://pratyushmaini.github.io/images/apple-touch-icon-57x57.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="60x60" href="https://pratyushmaini.github.io/images/apple-touch-icon-60x60.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="72x72" href="https://pratyushmaini.github.io/images/apple-touch-icon-72x72.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="76x76" href="https://pratyushmaini.github.io/images/apple-touch-icon-76x76.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="114x114" href="https://pratyushmaini.github.io/images/apple-touch-icon-114x114.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="120x120" href="https://pratyushmaini.github.io/images/apple-touch-icon-120x120.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="144x144" href="https://pratyushmaini.github.io/images/apple-touch-icon-144x144.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="152x152" href="https://pratyushmaini.github.io/images/apple-touch-icon-152x152.png?v=M44lzPylqQ"><link rel="apple-touch-icon" sizes="180x180" href="https://pratyushmaini.github.io/images/apple-touch-icon-180x180.png?v=M44lzPylqQ"><link rel="icon" type="image/png" href="https://pratyushmaini.github.io/images/favicon-32x32.png?v=M44lzPylqQ" sizes="32x32"><link rel="icon" type="image/png" href="https://pratyushmaini.github.io/images/android-chrome-192x192.png?v=M44lzPylqQ" sizes="192x192"><link rel="icon" type="image/png" href="https://pratyushmaini.github.io/images/favicon-96x96.png?v=M44lzPylqQ" sizes="96x96"><link rel="icon" type="image/png" href="https://pratyushmaini.github.io/images/favicon-16x16.png?v=M44lzPylqQ" sizes="16x16"><link rel="manifest" href="static/css/manifest.json"><link rel="mask-icon" href="https://pratyushmaini.github.io/images/safari-pinned-tab.svg?v=M44lzPylqQ" color="#000000"><link rel="shortcut icon" href="https://pratyushmaini.github.io/images/favicon.ico?v=M44lzPylqQ"><meta name="msapplication-TileColor" content="#000000"><meta name="msapplication-TileImage" content="https://pratyushmaini.github.io/images/mstile-144x144.png?v=M44lzPylqQ"><meta name="msapplication-config" content="https://pratyushmaini.github.io/images/browserconfig.xml?v=M44lzPylqQ"><meta name="theme-color" content="#ffffff"><link rel="stylesheet" href="static/css/academicons.css"> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script> <script type="text/x-mathjax-config"> MathJax.Hub.Config({ tex2jax: { inlineMath: [ ['$','$'], ["\\(","\\)"] ], processEscapes: true } }); </script> <script src='static/js/latest.js' async=""></script> <!-- end custom head snippets --></head><body> <!--[if lt IE 9]><div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div><![endif]--><div class="masthead"><div class="masthead__inner-wrap"><div class="masthead__menu"><nav id="site-nav" class="greedy-nav"> <button><div class="navicon"></div></button><ul class="visible-links"><li class="masthead__menu-item masthead__menu-item--lg"><a href="">Pratyush Maini</a></li><li class="masthead__menu-item"><a href="blog.html">Blog</a></li><li class="masthead__menu-item"><a href="teaching.html">Teaching</a></li><li class="masthead__menu-item"><a href="extra.html">Not Research</a></li></ul><ul class="hidden-links hidden"></ul></nav></div></div></div><div id="main" role="main"><div class="sidebar sticky"><div itemscope="" itemtype="http://schema.org/Person"><div class="author__avatar"> <img src="static/picture/Profile.jpg" class="author__avatar" alt="Pratyush Maini"></div><div class="author__content"><h3 class="author__name">Pratyush Maini</h3><p class="author__bio">PhD Student | Machine Learning | CMU</p></div><div class="author__urls-wrapper"> <button class="btn btn--inverse">Follow</button><ul class="author__urls social-icons"><li><i class="fa fa-fw fa-map-marker" aria-hidden="true"></i> Pittsburgh, PA</li><li><a href="mailto:pratyushmaini@cmu.edu"><i class="fas fa-fw fa-envelope" aria-hidden="true"></i> Email</a></li><li><a href="https://twitter.com/@pratyushmaini"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li><li><a href="https://www.linkedin.com/in/pratyush-maini"><i class="fab fa-fw fa-linkedin" aria-hidden="true"></i> LinkedIn</a></li><li><a href="https://github.com/pratyushmaini"><i class="fab fa-fw fa-github" aria-hidden="true"></i> Github</a></li><li><a href="https://scholar.google.com/citations?hl=en&user=2jPsTDgAAAAJ&view_op=list_works&citft=1&citft=2&citft=3&email_for_op=pratyush.maini%40gmail.com&gmla=AJsN-F4heOMwFmKXlgjaRdgzgIfXoFHAbZ8pTQryMKnUJwQ0NZXkv2Ls1CEn33LhONQ_8EnR-Tqd9tGvMpX72vH2kUBktQU5w9DQWVU9H2YX6BFlafpTgDob-ZmMzWc0YevGKbJeGVXISLdlgXd-zjrs_vdKVbG4lMbdpclHQdwREdqaFVbK9hiE8EMfLcFxqVjZTat0cOLjmEXsMTT9RweKeqC-kEt82RJ0xB7rQ9CS1NbO9vx-Ba2h90YnEpyUDT2-L7aiCHFy"><i class="fas fa-fw fa-graduation-cap"></i> Google Scholar</a></li></ul></div></div></div><article class="page" itemscope="" itemtype="http://schema.org/CreativeWork"><meta itemprop="headline" content=""><meta itemprop="description" content="About me"><div class="page__inner-wrap"><header><h1 class="page__title" itemprop="headline"></h1></header><section class="page__content" itemprop="text"> <script> function dropdown(divID) { var item = document.getElementById(divID); if (item) { item.className=(item.className=='hidden')?'unhidden':'hidden'; } } </script><p style="text-align: center;"><i> ~~ I like to Observe. Look for Patterns. Ponder over these Generalizations. Try to Refute them. <br> &nbsp;&nbsp; Or otherwise prove their Validity. And re-image their Applications in alternate spheres ~~ </i></p><h1 id="pratyush-maini">Pratyush Maini</h1><p>I am a PhD student in the Machine Learning Department at Carnegie Mellon Univeristy, and a founding member of <a href="http://www.datologyai.com">DatologyAI</a>. I am advised by <a href="http://zicokolter.com/">Prof. Zico Kolter</a> and <a href="https://acmilab.org">Prof. Zachary Lipton</a>. My research goal is to make Machine Learning systems trustworthy to the extent that they can be safely and reliably deployed outside the comfort of our research labs. <a href="javascript:dropdown('previously');">Previously,</a></p><div id="previously" class="hidden"> Previously, I spent a wonderful year working in the AI Solutions Lab at Samsung Research and Development Headquarters in South Korea. Before which I completed my bachelor's in Computer Science and Engineering from IIT Delhi. During my undergraduate years, I was fortunate to have had the opportunity to adapt and learn from the research styles of my amazing collaborators. I was advised by <a href="http://www.cse.iitd.ernet.in/~mausam/" target="_blank">Prof. Mausam</a> for my B.Tech. thesis, and worked with <a href="https://www.zicokolter.com" target="_blank">Prof. Zico Kolter</a>, <a href="https://www.cs.cmu.edu/~ericwong/" target="_blank">Eric Wong</a>, <a href="https://www.cs.cmu.edu/~ddanish/" target="_blank">Danish</a> at CMU, <a href="index3.html" target="_blank">Prof. Bo Li</a>, <a href="https://people.eecs.berkeley.edu/~dawnsong/" target="_blank">Prof. Dawn Song</a>, <a href="index4.html" target="_blank">Xinyun Chen</a> at UIUC/UC Berkeley, <a href="https://www.papernot.fr" target="_blank">Prof. Nicolas Papernot</a> at UofT/Vector and <a href="https://people.epfl.ch/james.larus" target="_blank">Prof. James Larus</a> at EPFL during research internships. <br> <br></div><p><strong>Collaborate?</strong> I am always excited to exchange research perspectives and hop on to new research endeavors. If you are interested, reach out via email!</p><p><strong>Bio:</strong> If you need a bio for a talk, please use <a href="javascript:dropdown('bio');">this:</a></p><div id="bio" class="hidden"><blockquote> Pratyush is a Ph.D. student in the Machine Learning Department at Carnegie Mellon University, and a founding member of DatologyAI. In his work, he has developed scalable and performant methods for improving the quality of data that we train machine learning models on. He has also developed methods that allow us to evaluate, locate, and mitigate the memorization of data points by neural networks. His works have been recognized through a best paper award nomination at NeurIPS, and multiple oral and spotlight talks at important ML conferences.</blockquote></div><h2 id="talks">Talks</h2><ul><li>April 2024: TOFU @ <a href="https://www.amazon.science/tag/responsible-ai">Responsible AI Reading Group at AWS</a></li><li>April 2024: Rephrasing The Web @ <a href="https://www.together.ai/research">Together AI Research Group</a></li><li>March 2024: Rephrasing The Web @ <a href="https://sambanova.ai/blog/accurate-models-at-blazing-speed">Sambanova Research Group</a></li><li>February 2024: Can Neural Network Memorization be Localized @ <a href="http://ml-ka.slack.com/">ML PDG Karlsruhe</a></li><li>November 2023: Can Neural Network Memorization be Localized @ <a href="index5.html">Ellis Reading Group on Mathematics of Deep Learning</a></li><li>October 2023: T-MARS @ <a href="https://www.datacomp.ai/workshop.html">ICCV 2023, Datacomp Workshop</a></li><li>September 2023: T-MARS @ <a href="https://people.csail.mit.edu/ludwigs/">Ludwig Schmidt’s lab</a></li><li>June 2022: Characterizing Datapoints via Second-split Forgetting @ SCIS ICML 2022</li></ul><h2 id="publications">Publications</h2><p>(12) <a href="https://arxiv.org/abs/2404.07177" target="_blank">Scaling Laws for Data Filtering—Data Curation cannot be Compute Agnostic</a> <br> <em>Sachin Goyal*, Pratyush Maini*, Zachary C. Lipton, Aditi Raghunathan, J. Zico Kolter</em> <br> <strong>CVPR</strong> 2024 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> Data Problems for Foundation Models (<strong>ICLR</strong>) 2024 <img src="static/picture/-workshop-blue.svg" alt=""> <img src="static/picture/-best_paper_award-red.svg" alt=""> <br> <a href="javascript:dropdown('fadu-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2401.16380" target="_blank">Paper</a> | <a href="javascript:dropdown('fadu-cite');">Citation</a></p><div id="fadu-tldr" class="hidden"><b>TLDR:</b> Data curation decisions must consider the total compute a model is being trained for.<br><br></div><div id="fadu-cite" class="hidden"><pre>@inproceedings{goyal2024scaling,
  title={Scaling Laws for Data Filtering—Data Curation cannot be Compute Agnostic},
  author={Goyal, Sachin and Maini, Pratyush and Lipton, Zachary C and Raghunathan, Aditi and Kolter, J Zico},
  booktitle={CVPR2024},
  year={2024}
}</pre></div><p>(11) <a href="https://huggingface.co/papers/2401.16380" target="_blank">Rephrasing the Web: A Recipe for Compute &amp; Data-Efficient Language Modeling</a> <br> <em>Pratyush Maini*, Skyler Seto*, He Bai, David Grangier, Yizhe Zhang, Navdeep Jaitly</em> <br> <a href="javascript:dropdown('rephrase-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2401.16380" target="_blank">Paper</a> | <a href="javascript:dropdown('rephrase-cite');">Citation</a></p><div id="rephrase-tldr" class="hidden"><b>TLDR:</b> You can train 3x faster and with upto 10x lesser data with just synthetic rephrases of the web!<br><br></div><div id="rephrase-cite" class="hidden"><pre>@inproceedings{maini2024rephrasing,
  title={Rephrasing the Web: A Recipe for Compute &amp; Data-Efficient Language Modeling},
  author={Maini, Pratyush and Seto, Skyler and Bai, He and Grangier, David and Zhang, Yizhe and Jaitly, Navdeep},
  booktitle={arXiv},
  year={2024}
}</pre></div><p>(10) <a href="tofu.html" target="_blank">TOFU: A Task of Fictitious Unlearning for LLMs</a> <br> <em>Pratyush Maini*, Zhili Feng*, Avi Schwarzschild*, Zachary C. Lipton, J. Zico Kolter</em> <br> Set-LLM @ ICLR 2024 <img src="static/picture/-workshop-blue.svg" alt=""> <img src="static/picture/-oral-red.svg" alt=""> <br> <a href="javascript:dropdown('tofu-drop-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2401.06121" target="_blank">Paper</a> | <a href="tofu.html" target="_blank">Website</a> | <a href="javascript:dropdown('tofu-drop');">Citation</a></p><div id="tofu-drop-tldr" class="hidden"><b>TLDR:</b> Synthetic data benchmark for machine unlearning for LLMs <br><br></div><div id="tofu-drop" class="hidden"><pre>@misc{tofu2024,
      title={TOFU: A Task of Fictitious Unlearning for LLMs}, 
      author={Pratyush Maini and Zhili Feng and Avi Schwarzschild and Zachary C. Lipton and J. Zico Kolter},
      year={2024},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}</pre></div><p>(9) <a href="mem_web.html" target="_blank">Can Neural Network Memorization be Localized?</a> <br> <em>Pratyush Maini, Michael Curtis Mozer, Hanie Sedghi, Zachary Chase Lipton, J Zico Kolter, Chiyuan Zhang</em> <br> International Conference on Machine Learning (<strong>ICML</strong>) 2023 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> <a href="javascript:dropdown('mem-drop-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2307.09542" target="_blank">Paper</a> | <a href="mem_web.html" target="_blank">Website</a> | <a href="static/file/mem_drop_Slides.pdf" target="_blank">Slides</a> | <a href="static/file/mem_drop_Slides.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('mem-drop');">Citation</a></p><div id="mem-drop-tldr" class="hidden"><b>TLDR:</b><ol><li>We show that memorization is typically not localized to specific model layers, rather is confined to a small fraction of neurons dispersed across the model.</li><li>We propose Example-Tied Dropout that can confine memorization to a pre-defined set of neurons, which can then be thrown away at test time.</li></ol><br><br></div><div id="mem-drop" class="hidden"><pre>@inproceedings{maini2023memorization,
  title={Can Neural Network Memorization Be Localized?},
  author={Maini, Pratyush and Mozer, Michael C and Sedghi, Hanie and Lipton, Zachary C and Kolter, J Zico and Zhang, Chiyuan},
  booktitle={International Conference on Machine Learning},
  year={2023}
}</pre></div><p>(8) <a href="https://arxiv.org/abs/2307.03132" target="_blank">T-MARS: Improving Visual Representations by Circumventing Text Feature Learning</a> <br> <em>Pratyush Maini*, Sachin Goyal*, Zachary C. Lipton, Zico Kolter, Aditi Raghunathan</em> <br> ICLR 2024 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> DMLR @ International Conference on Machine Learning (<strong>ICML</strong>) 2023 <img src="static/picture/-workshop-blue.svg" alt=""><br> Datacomp Workshop @ <strong>ICCV</strong> 2023 <img src="static/picture/-workshop-blue.svg" alt=""> <img src="static/picture/-contributed_oral-red.svg" alt=""> <br> <a href="javascript:dropdown('tmars-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2307.03132" target="_blank">Paper</a> | <a href="index6.html" target="_blank">Website</a> | <a href="static/file/mem_drop_Slides.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('tmars');">Citation</a></p><div id="tmars-tldr" class="hidden"><b>TLDR:</b> We propose an algorithm to filter web datasets used for training CLIP in order to learn better visual representations, and achieve state-of-art zeroshot accuracy on vision tasks. <br><br></div><div id="tmars" class="hidden"><pre>@article{maini2023tmars,
  title={T-MARS: Improving Visual Representations by Circumventing Text Feature Learning},
  author={Maini, Pratyush and Goyal, Sachin and Lipton, Zachary C and Kolter, J Zico and Raghunathan, Aditi},
  booktitle={Arxiv},
  year={2023}
}</pre></div><p>(7) <a href="https://arxiv.org/abs/2303.07320" target="_blank">Model-tuning Via Prompts Makes NLP Models Adversarially Robust</a> <br> <em>Mrigank Raman*, Pratyush Maini*, Zico Kolter, Zachary C. Lipton, Danish Pruthi</em> <br> EMNLP 2023 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> AdvML-Frontiers @ International Conference on Machine Learning (<strong>ICML</strong>) 2023 <img src="static/picture/-workshop-blue.svg" alt=""><br> <a href="javascript:dropdown('ssft-tldr');">TLDR</a> | <a href="https://openreview.net/forum?id=yKDKNzjHg8N" target="_blank">Paper</a> | <a href="" target="_blank">Video</a> | <a href="static/file/SSFT_Slides.pdf" target="_blank">Slides</a> | <a href="static/file/SSFT_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('ssft');">Citation</a></p><div id="ssft-tldr" class="hidden"><b>TLDR:</b><ol><li>We analyze the forgetting and learning dynamics of neural networks to characterize different types of hard examples as belonging to mislabeled, rare and complex categories.</li><li>Mislabeled Examples : Learnt Late, Forgotten Early</li><li>Rare Examples: Learnt Late, Forgotten Late</li><li>Complex Examples: Learnt Late, Never Forgotten</li></ol><br><br></div><p>(6) <a href="https://openreview.net/forum?id=bCdztvpaEUG" target="_blank">Characterizing Datapoints via Second-Split Forgetting</a> <br> <em>Pratyush Maini, Saurabh Garg, Zachary C. Lipton, Zico Kolter</em> <br> Conference on Neural Information Processing Systems(<strong>NeurIPS</strong>) 2022 <img src="static/picture/-conference-brightgreen.svg" alt=""> <img src="static/picture/-award_nomination-red.svg" alt=""> <br> SCIS @ International Conference on Machine Learning (<strong>ICML</strong>) 2022 <img src="static/picture/-workshop-blue.svg" alt=""> <img src="static/picture/-oral-red.svg" alt=""> <br> <a href="javascript:dropdown('ssft-tldr');">TLDR</a> | <a href="https://openreview.net/forum?id=yKDKNzjHg8N" target="_blank">Paper</a> | <a href="" target="_blank">Video</a> | <a href="static/file/SSFT_Slides.pdf" target="_blank">Slides</a> | <a href="static/file/SSFT_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('ssft');">Citation</a></p><div id="ssft-tldr" class="hidden"><b>TLDR:</b><ol><li>We analyze the forgetting and learning dynamics of neural networks to characterize different types of hard examples as belonging to mislabeled, rare and complex categories.</li><li>Mislabeled Examples : Learnt Late, Forgotten Early</li><li>Rare Examples: Learnt Late, Forgotten Late</li><li>Complex Examples: Learnt Late, Never Forgotten</li></ol><br><br></div><div id="ssft" class="hidden"><pre>@inproceedings{
	maini2022characterizing,
	title={Characterizing Datapoints via Second-Split Forgetting},
	author={Pratyush Maini and Saurabh Garg and Zachary Chase Lipton and J Zico Kolter},
	booktitle={Advances in Neural Information Processing Systems},
	editor={Alice H. Oh and Alekh Agarwal and Danielle Belgrave and Kyunghyun Cho},
	year={2022},
	url={https://openreview.net/forum?id=yKDKNzjHg8N}
}</pre></div><p>(5) <a href="https://openreview.net/pdf?id=hvdKKV2yt7T" target="_blank">Dataset Inference: Ownership Resolution in Machine Learning</a> <br> <em>Pratyush Maini, Mohammad Yaghini, Nicolas Papernot</em> <br> International Conference on Learning Representations (<strong>ICLR</strong>) 2021 <img src="static/picture/-conference-brightgreen.svg" alt=""> <img src="static/picture/-spotlight-yellow.svg" alt=""> <br> Privacy Preserving Machine Learning (<strong>PPML</strong>) Workshop at <strong>NeurIPS</strong> 2020 <img src="static/picture/-workshop-blue.svg" alt=""> <br> Workshop on Dataset Curation and Security (<strong>WDCS</strong>) at <strong>NeurIPS</strong> 2020 <img src="static/picture/-workshop-blue.svg" alt=""> <br> <a href="javascript:dropdown('di-tldr');">TLDR</a> | <a href="https://openreview.net/forum?id=hvdKKV2yt7T" target="_blank">Paper</a> | <a href="https://slideslive.com/38940925/dataset-inference-ownership-resolution-in-machine-learning" target="_blank">Video</a> | <a href="static/file/mem_drop_Slides.pdf" target="_blank">Slides</a> | <a href="static/file/DI_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('di');">Citation</a></p><div id="di-tldr" class="hidden"><b>TLDR:</b><ol><li>Dataset Inference (DI) resolves model ownership without the need for retraining; and does not have a trade-off with task accuracy.</li><li>We prove that the success of Membership Inference decreases as overfitting reduces, whereas DI is independent of the same.</li><li>We introduce a new method for black-box ownership resolution that requires less than 50 private training points from the victim’s dataset.</li></ol><br><br></div><div id="di" class="hidden"><pre>@article{maini2021dataset,
	title={Dataset Inference: Ownership Resolution in Machine Learning},
	author={Pratyush Maini and Mohammad Yaghini and Nicolas Papernot},
	booktitle={ICLR 2021},
	year={2020},
	url={https://openreview.net/forum?id=hvdKKV2yt7T},
	note={Spotlight at ICLR 2021}
}</pre></div><p>(4) <a href="https://arxiv.org/abs/2011.14779" target="_blank">Data-Free Model Extraction</a> <br> <em>Jean-Baptiste Truong*, Pratyush Maini*, Robert Walls, Nicolas Papernot</em> <br> Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>) 2021 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> <a href="javascript:dropdown('dfme-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/2011.14779" target="_blank">Paper</a> | <a href="https://github.com/cake-lab/datafree-model-extraction" target="_blank">Code</a> | <a href="static/file/DI_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('dfme');">Citation</a></p><div id="dfme-tldr" class="hidden"><b>TLDR:</b> We analyze the importance of similarity between surrogate &amp; victim datasets for the success of model stealing attacks, and develop a method to steal ML models with zero knowledge of the victim’s training data.<br><br></div><div id="dfme" class="hidden"><pre>@article{truong2021data,
	title={Data-Free Model Extraction},
	author={Jean-Baptiste Truong* and Pratyush Maini* and Robert J. Walls and Nicolas Papernot},
	booktitle={arXiv preprint arXiv:2011.14779},
	year={2021},
	url={https://arxiv.org/abs/2011.14779},
	note={under review at CVPR 2021},
}</pre></div><p>(3) <a href="https://openreview.net/pdf?id=Oe2XI-Aft-k" target="_blank">Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness</a> <br> <em>Pratyush Maini, Xinyun Chen, Bo Li, Dawn Song</em> <br> Conference on Uncertainty in Artificial Intelligence (<strong>UAI</strong>) 2022 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> <strong>ICML</strong> Workshop on Uncertainty and Robustness in Deep Learning <img src="static/picture/-workshop-blue.svg" alt=""> <br> <a href="javascript:dropdown('protector-tldr');">TLDR</a> | <a href="https://openreview.net/pdf?id=Oe2XI-Aft-k" target="_blank">Paper</a> | <a href="javascript:dropdown('protector');">Citation</a></p><div id="protector-tldr" class="hidden"><b>TLDR:</b> We demonstrate that adversarial perturbations belonging to different threat models can be separated, and use this intuition to propose a two stage pipeline <i>PROTECTOR</i> that is robust against multiple perturbation types.<br><br></div><div id="protector" class="hidden"><pre>@InProceedings{maini2022perturbation,
  title = 	 {Perturbation Type Categorization for Multiple $\ell_p$ Bounded Adversarial Robustness},
  author =       {Pratyush Maini and Xinyun Chen and Bo Li and Dawn Song},
  booktitle = 	 {Proceedings of The 38th Uncertainty in Artificial Intelligence Conference},
  year = 	 {2022},
  series = 	 {Proceedings of Machine Learning Research},
  url={https://openreview.net/pdf?id=Oe2XI-Aft-k},
}</pre></div><p>(2) <a href="https://arxiv.org/abs/1909.04068" target="_blank">Adversarial Robustness Against the Union of Multiple Perturbation Models</a> <br> <em>Pratyush Maini, Eric Wong, Zico Kolter</em> <br> International Conference on Machine Learning (<strong>ICML</strong>) 2020 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> <a href="javascript:dropdown('multiple-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/1909.04068" target="_blank">Paper</a> | <a href="http://test.slideslive.com/38928141/adversarial-robustness-against-the-union-of-multiple-petrubation-models?ref=speaker-31494-latest" target="_blank">Video</a> | <a href="static/file/robust_union.pdf" target="_blank">Slides</a> | <a href="https://github.com/locuslab/robust_union" target="_blank">Code</a> | <a href="javascript:dropdown('multiple');">Citation</a></p><div id="multiple-tldr" class="hidden"><b>TLDR:</b> We develop a generalization of the standard PGD-based procedure to train architectures which are robust against multiple perturbation models, outperforming past approaches on the MNIST and CIFAR10 datasets.<br><br></div><div id="multiple" class="hidden"><pre>@inproceedings{maini2020adversarial,
	title={Adversarial Robustness Against the Union of Multiple Perturbation Models}, 
	author={Pratyush Maini and Eric Wong and J. Zico Kolter},
	booktitle={International Conference on Machine Learning},
	year={2020},
	url = "https://arxiv.org/abs/1909.04068"
}</pre></div><p>(1) <a href="https://arxiv.org/abs/2005.00159" target="_blank">Why and when should you pool? Analyzing Pooling in Recurrent Architectures</a> <br> <em>Pratyush Maini, Keshav Kolluru, Danish Pruthi, Mausam</em> <br> <strong>EMNLP</strong> (Findings) 2020 <img src="static/picture/-conference-brightgreen.svg" alt=""> <br> <strong>BlackBoxNLP</strong> 2020 <img src="static/picture/-workshop-blue.svg" alt=""> <br> <a href="javascript:dropdown('pooling-tldr');">TLDR</a> | <a href="https://arxiv.org/abs/1909.04068" target="_blank">Paper</a> | <a href="" target="_blank">Video</a> | <a href="static/file/mem_drop_Slides.pdf" target="_blank">Slides</a> | <a href="https://github.com/dair-iitd/PoolingAnalysis" target="_blank">Code</a> | <a href="Pooling-Analysis.html" target="_blank">Blog</a> | <a href="static/file/Pooling_Poster.pdf" target="_blank">Poster</a> | <a href="javascript:dropdown('pooling');">Citation</a></p><div id="pooling-tldr" class="hidden"><b>TLDR:</b><ol><li> Pooling (and attention) help improve learning ability and positional invariance of BiLSTMs.</li><li> Pooling helps improve sample efficiency (low-resource settings) and is particularly beneficial when important words lie away from the end of the sentence.</li><li> Our proposed pooling technique, max-attention (MaxAtt), helps improve upon past approaches on standard accuracy metrics, and is more robust to distribution shift.</li></ol><br><br></div><div id="pooling" class="hidden"><pre>@inproceedings{maini2020pool,
	title = "Why and when should you pool? Analyzing Pooling in Recurrent Architectures",
	author = "Maini, Pratyush and Kolluru, Keshav and Pruthi, Danish and {Mausam}",
	booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2020",
	year = "2020",
	address = "Online",
	publisher = "Association for Computational Linguistics",
	url = "https://www.aclweb.org/anthology/2020.findings-emnlp.410",
	note = {Also presented at BlackBoxNLP'20}
}</pre></div><hr><p>* = equal contribution</p><h2 id="academic-service">Academic Service</h2><p>Reviewer for: <br> <em>ML:</em> <strong>NeurIPS</strong> 2022, 2021, 2020<em>; <strong>ICLR</strong> 2022 (Highlighted Reviewer), 2021*; <strong>ICML</strong> 2022 <br> *NLP:</em> <strong>NAACL</strong> 2021; <strong>EMNLP</strong> 2022, 2021 <br> <em>Others:</em> <strong>IEEE S&amp;P</strong> 2021*, <strong>CVPR</strong> 2022, <strong>AISTATS</strong> 2022</p><hr><p>* = external reviewer</p></section><footer class="page__meta"></footer></div></article></div><div class="page__footer"><footer> <!-- start custom footer snippets --> <a href="sitemap.html">Sitemap</a> <!-- end custom footer snippets --><div class="page__footer-follow"><ul class="social-icons"> <!--<li><strong>Follow:</strong></li><li><a href="https://facebook.com/pratyush.maini"><i class="fab fa-facebook-square" aria-hidden="true"></i> Facebook</a></li><li><a href="http://github.com/pratyushmaini"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a></li>--> <!--<li><a href="https://pratyushmaini.github.io/feed.xml"><i class="fa fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>--></ul></div><div class="page__footer-copyright">&copy; 2024 Pratyush Maini. Powered by <a href="http://jekyllrb.com" rel="nofollow">Jekyll</a> &amp; <a href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div></footer></div><script src="static/js/main.min.js"></script> <script> (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){ (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o), m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m) })(window,document,'script','//www.google-analytics.com/analytics.js','ga'); ga('create', '', 'auto'); ga('send', 'pageview'); </script></body></html>
